{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model compression\n",
    "\n",
    "There exists a few methods to compress the model without a significant loss in performance:\n",
    "\n",
    "- Pruning: Removing weights with a low weight\n",
    "- Quantization: Quantization reduces the precision of weights and activation\n",
    "- Knowledge distillation: Train a smaller (student) model to mimin the behviour of a larger (teacher) model. \n",
    "\n",
    "For this task, pruning will be conducted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models\n",
    "import torch.nn.utils.prune as prune\n",
    "\n",
    "\n",
    "data_dir = \"../data/test\"\n",
    "labels = ['fresh','blackspot','canker','grenning']\n",
    "model_file_input = '../models/cross_validation_final.pth'\n",
    "pruning_amount = 0.2\n",
    "model_file_output = '../models/cross_validation_final_pruned.pth'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.mobilenet_v2()\n",
    "model.classifier[1] = torch.nn.Linear(model.classifier[1].in_features, len(labels))\n",
    "model.load_state_dict(torch.load(model_file_input, weights_only=True))\n",
    "model = model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply pruning\n",
    "\n",
    "Apply pruning with a predefined pruning_amount (e.g. 20%). This means that the 20% lowest weight get set to 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to apply pruning to all Conv2d layers\n",
    "def apply_pruning(model, amount=pruning_amount):\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, torch.nn.Conv2d):\n",
    "            prune.l1_unstructured(module, name='weight', amount=amount)\n",
    "apply_pruning(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate pruning\n",
    "\n",
    "Count the number of weights that are set to zero. This should match the number that was specified before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total weights: 2189760\n",
      "Pruned weights: 437952\n",
      "Pruned percentage: 20.00%\n"
     ]
    }
   ],
   "source": [
    "# Function to count the pruned weights\n",
    "def count_pruned_weights(model):\n",
    "    total_weights = 0\n",
    "    pruned_weights = 0\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, torch.nn.Conv2d):\n",
    "            # The mask is stored in 'weight_mask' after pruning\n",
    "            if hasattr(module, 'weight_mask'):\n",
    "                weight_mask = module.weight_mask\n",
    "                total_weights += weight_mask.numel()\n",
    "                pruned_weights += (weight_mask == 0).sum().item()\n",
    "    return pruned_weights, total_weights\n",
    "\n",
    "pruned_weights, total_weights = count_pruned_weights(model)\n",
    "pruned_percentage = 100 * pruned_weights / total_weights\n",
    "\n",
    "print(f\"Total weights: {total_weights}\")\n",
    "print(f\"Pruned weights: {pruned_weights}\")\n",
    "print(f\"Pruned percentage: {pruned_percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove weights and store model to file\n",
    "\n",
    "Remove weights from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pruning(model):\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, torch.nn.Conv2d):\n",
    "            if hasattr(module, 'weight_mask'):\n",
    "                prune.remove(module, 'weight')\n",
    "\n",
    "remove_pruning(model)\n",
    "\n",
    "torch.save(model.state_dict(), model_file_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "After this notebook, the resulting model was evaluated with the model_validation notebook. A pruninig amount of 20% did not lead to too much performance loss while reducing the amount of weights considerably. Depending on that application, the model should run on, further methods would be required."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
